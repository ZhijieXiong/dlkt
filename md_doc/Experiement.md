[TOC]

# 实验结果汇报

## Our setting (Knowledge Tracing)

- 该实验设置下，数据处理过程如下

- 数据预处理：序列长度固定为200，截长补短，丢弃长度小于3的序列

  数据集划分：以序列为单位，5折交叉验证划分训练集和测试集，再在每折训练集中随机划分20%做验证集

  随机种子：所有实验都固定随机种子为0

  超参选择：在第1折上调参，根据验证集选择最好的超参，然后应用到5折上

  模型训练停止策略：early stop，如果验证集上AUC指标在10个epoch内提升不超过0.001，则停止训练，最大epoch数为200

  对比方法：原论文实验设置下复现论文汇报结果后，再拉到我们的实验设置下统一做实验，都在原论文所提到的空间中调参

  汇报结果：5折下测试集的均值，指标为AUC

- 运行`example/prepare_dataset/our_setting.py`获得划分好的数据集

- 该实验设置下所有的超参数均可在`example/scripts/our_setting`下的脚本中获得

- 根据我们的经验，知识追踪模型对超参数敏感度低，所以即使是不同的实验设置，也可以使用该实验设置下的超参数来训练模型，无需再次调参

### Overall metric (AUC)

- 常规指标，计算所有样本的性能，汇报AUC指标

|           | Assist2009 | Assist2012 | Statics2011 | Ednet-KT1 | Xes3g5m | Slemapy-Anatomy |
| :-------: | :--------: | :--------: | :---------: | :-------: | :-----: | :-------------: |
|    DKT    |   0.7481   |   0.7337   |   0.6612    |  0.7113   | 0.7838  |     0.6838      |
|   DKVMN   |   0.7456   |   0.7217   |    0.668    |  0.7046   | 0.7748  |     0.6745      |
|   SAKT    |   0.7328   |   0.721    |   0.6642    |  0.6776   | 0.7791  |      0.676      |
|   LPKT    |   0.7682   |   0.7884   |   0.7394    |  0.8216   | 0.8257  |     0.7365      |
|   DIMKT   |   0.7647   |   0.7845   |   0.7154    |  0.8198   | 0.8262  |     0.7285      |
| SimpleKT  |   0.7853   |   0.7818   |   0.7342    |  0.8214   | 0.8198  |     0.7316      |
|   QIKT    |   0.7843   |   0.7753   |   0.7329    |  0.8268   | 0.8232  |     0.7234      |
| SparseKT  |   0.7782   |   0.7727   |   0.7302    |  0.8162   | 0.8153  |     0.7258      |
|   MIKT    |   0.7886   |   0.7902   |   0.7436    |  0.8213   | 0.8179  |     0.7369      |
|    AKT    |   0.7854   |   0.7904   |   0.7345    |  0.8193   | 0.8225  |     0.7288      |
|   qDKT    |   0.7684   |   0.7861   |   0.7354    |  0.8191   | 0.8252  |     0.7247      |
| AKT-CORE  |   0.7512   |   0.7619   |   0.7076    |  0.7811   | 0.8037  |     0.7133      |
| qDKT-CORE |   0.7365   |   0.7527   |   0.6544    |  0.7608   |  0.78   |     0.7008      |

|          | Assist2017 | Junyi2015 |    Edi2020-task1    |   Edi2020-task34    |
| :------: | :--------: | :-------: | :-----------------: | :-----------------: |
|   qDKT   |   0.7919   |  0.7806   |       0.8141        |       0.7947        |
|   AKT    |   0.772    |  0.7791   |       0.8129        |        0.793        |
|   LPKT   |   0.812    |  not run  |       0.8179        |       0.7968        |
|  DIMKT   |   0.8002   |  0.7836   |       0.8138        |       0.7936        |
| SimpleKT |   0.7746   |  0.7793   |       0.8135        |       0.7937        |
|   QIKT   |   0.7874   |  0.7812   |         OOM         |       0.7972        |
|   LBKT   |   0.8335   |  0.7829   | Lack of information | Lack of information |

`LBKT` in `Assist2009`: 0.7767

`LBKT` in `Assist2012`: 0.7914

### CORE metric (AUC)

- 论文`"Model-agnostic counterfactual reasoning for identifying and mitigating answer bias in knowledge tracing", Neural Networks 2024`提出来的一种无偏指标，汇报AUC指标

|          | Assist2009 | Assist2012 | Statics2011 | Statics | Xes3g5m | Slemapy-Anatomy |
| :------: | :--------: | :--------: | :---------: | :-----: | :-----: | :-------------: |
|   DKT    |   0.6931   |   0.6716   |   0.5857    | 0.6447  | 0.7031  |     0.6681      |
|  DKVMN   |   0.6859   |   0.6615   |   0.5817    | 0.6468  | 0.6979  |     0.6622      |
|   SAKT   |   0.6755   |   0.6582   |   0.5806    | 0.6283  | 0.7003  |     0.6651      |
|   LPKT   |   0.6559   |   0.6684   |   0.5712    | 0.6061  | 0.7097  |     0.6789      |
|  DIMKT   |   0.6821   |   0.664    |   0.5671    | 0.6131  | 0.7102  |     0.6679      |
| SimpleKT |   0.6903   |   0.6607   |   0.5722    | 0.6155  | 0.7002  |     0.6712      |
|   QIKT   |   0.6776   |   0.6469   |   0.5652    | 0.6262  | 0.7076  |     0.6634      |
| SparseKT |   0.6754   |   0.6438   |   0.5591    | 0.6025  | 0.6914  |     0.6667      |
|   MIKT   |   0.6874   |   0.6673   |   0.5809    | 0.6161  | 0.6895  |     0.6791      |
|   AKT    |   0.6955   |   0.6789   |   0.5769    | 0.6173  | 0.7127  |     0.6776      |
|   qDKT   |   0.6826   |   0.666    |   0.5708    | 0.6146  | 0.7078  |      0.665      |
| AKT-CORE |   0.6966   |   0.6965   |   0.5858    | 0.6319  | 0.7315  |     0.6902      |

## Our DG setting (Knowledge Tracing)

- 域泛化实验设置，具体如下
- Assist2009和Assist2012数据集有学生学校信息，所以可以基于学校做域泛化的实验，实验设置如下

  1、 合并人数少的学校为一个学校，同时不将极端学校（序列平均长度小于20）作为测试集数据。

  2、合并完成后，首先以学校为单位随机划分80%的学校为训练集，并且要求训练集的样本数量占总样本数量的70%～85%。

  3、划分训练集和测试集后，以学生为单位从训练集中划分20%作为验证集

  4、通过随机划分得到10种不同划分情况，用qDKT测量模型在验证集和测试集上的性能gap

  5、选择gap最大的结果做实验，为了降低随机性，汇报结果为5个随机种子的结果取平均

  6、模型停止训练的方法仍然是early stop，选择验证集性能最高的模型

  7、因为验证集是I.I.D的，所以各个模型的参数和our setting一样，并没有调参

  Slepemapy-Anatomy数据集有学生城市信息，所以可以基于城市做域泛化的实验，由于该数据集中其中一个城市的学生数据占比达到80%，所以直接使用该城市学生数据作为训练集，剩余数据作为测试集
- 汇报结果，使用AUC指标，括号外为验证集（I.I.D.）性能，括号内为测试集（O.O.D.）性能

### AUC Metric

|       | Assist2009      | Assist2012      | Slepemapy-Anatomy |
| ----- | --------------- | --------------- | ----------------- |
| qDKT  | 0.7482 (0.7327) | 0.7748 (0.7523) | 0.7258 (0.7096)   |
| AKT   | 0.7558 (0.7321) | 0.7766 (0.7506) | 0.7303 (0.7129)   |
| LPKT  | 0.7525 (0.7416) | 0.7787 (0.7577) | 0.7423 (0.7238)   |
| DIMKT | 0.7247 (0.7386) | 0.7724 (0.7449) | 0.7303 (0.7139)   |
| LBKT  | 0.7603 (0.7482) | 0.779 (0.7574)  |                   |

## pyKT setting (Knowledge Tracing)

- 要查看完整的实验记录，请点击[此处](https://docs.qq.com/sheet/DREdTc3lVQWJkdFJw?tab=BB08J2)。

- **调参是在 `example/prepare_datset/our_setting` 实验设置下进行的。我们在 `pykt_question_setting` 中直接使用了 `our_setting` 的参数，因此复现结果与论文中报告的结果略有不同。**，然后取5折的平均值（为了减少随机性，所有实验的随机种子都固定为0）。括号中的值是论文报告结果。表中的汇报指标为`AUC`。

- 论文中报告结果来自 `pyKT`、`SimpleKT`、`AT-DKT` 和 `QIKT`。请参阅[相应的论文](md_doc/MODELS.md)。

- 由于 `ATKT` 的原始代码存在数据泄漏问题，我们使用了 `pyKT` 提供的 `atktfix`。

- 下表是在多知识点数据集上的复现结果，请注意：

  1. 我们并没有像 `pyKT` 那样首先将练习序列扩展为知识概念序列（见 `pyKT` 论文图2），然后在知识概念序列上训练模型，最后在问题上测试模型（见 `pyKT` 论文第3.3节）。我们的复现是直接在问题序列上训练和测试模型，也就是说，对于多概念问题，我们使用 `mean pooling` 来处理多个概念嵌入。
  2. 这种差异不仅体现在模型的训练和测试上，还体现在数据预处理上。`pyKT` 首先扩展序列，然后切分序列，固定每个序列的长度为200。而我们是直接切分序列，固定序列长度为200。

  |          |   Assist2009   |     AL2005     |     BD2006     |    xes3g5m     |
  | :------: | :------------: | :------------: | :------------: | :------------: |
  |   DKT    | 0.756(0.7541)  | 0.8162(0.8149) | 0.7748(0.8015) | 0.7849(0.7852) |
  |   AKT    | 0.7911(0.7853) | 0.8169(0.8306) | 0.8162(0.8208) | 0.8231(0.8207) |
  | SimpleKT | 0.7906(0.7744) | 0.8426(0.8254) | 0.8144(0.816)  | 0.821(0.8163)  |
  |   QIKT   | 0.7907(0.7878) |      OOM       |      OOM       |      todo      |
  |   qDKT   |     0.7762     |     0.8363     |     0.8144     | 0.8261(0.8225) |

- 下表是在单知识点数据集上的复现结果，请注意：

  1. 对于问题数量较少的数据集，我们的 DKT 和 ATKT 也提供了以问题作为条目的结果。
  2. 对于 `statics2011` 和 `edi2020-task34` 数据集，我们的数据预处理与 `pyKT` 不同。

|           |  Statics2011   |     NIPS34     |
| :-------: | :------------: | :------------: |
|    DKT    |     0.7142     | 0.762(0.7681)  |
|  DKT_que  | 0.8161(0.8222) | 0.7935(0.7995) |
|   DKVMN   |     0.7066     | 0.7512(0.7673) |
| DKVMN_que | 0.8078(0.8093) |     0.7901     |
|   SAINT   | 0.7273(0.7599) | 0.7846(0.7873) |
|   ATKT    |     0.696      | 0.7603(0.7665) |
| ATKT_que  | 0.8018(0.8055) |     0.7844     |
|    AKT    | 0.8244(0.8309) | 0.7943(0.8033) |
| SimpleKT  | 0.8258(0.8199) | 0.7955(0.8035) |
|  AT-DKT   |      todo      |      todo      |
|   QIKT    |     0.8303     | 0.7993(0.8044) |
|   qDKT    |     0.8236     |     0.7968     |

## Other Setting (Knowledge Tracing)

- 要查看完整的实验记录，请点击[这里](https://docs.qq.com/sheet/DREtXSUtqTkZrTVVY?tab=BB08J2)

## NCD Setting (Cognitive Diagnosis)

- 论文：`"Neural Cognitive Diagnosis for Intelligent Education Systems"`	

| Assist2009 | AUC    | ACC    | RMSE   |
| ---------- | ------ | ------ | ------ |
| paper      | 0.749  | 0.719  | 0.439  |
| repro      | 0.7551 | 0.7236 | 0.4328 |

